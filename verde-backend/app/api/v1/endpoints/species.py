from fastapi import APIRouter, Query, Depends
from typing import Optional, Dict, Any, List
from app.services.iucn_service import iucn_service
from app.database import get_db
from app.models.search_history import SearchHistory
from sqlalchemy.orm import Session
from sqlalchemy import func
from datetime import datetime, timedelta
import difflib

router = APIRouter()

# í•œê¸€-ì˜ë¬¸ ì¢… ì´ë¦„ ë§¤í•‘
SPECIES_TRANSLATIONS = {
    # ë™ë¬¼
    'íŒë‹¤': ['panda', 'giant panda', 'ailuropoda'],
    'íŒ¬ë”': ['panda', 'giant panda', 'ailuropoda'],
    'í˜¸ë‘ì´': ['tiger', 'panthera tigris', 'amur tiger', 'siberian tiger'],
    'íƒ€ì´ê±°': ['tiger', 'panthera tigris'],
    'ê³°': ['bear', 'ursus', 'grizzly', 'polar'],
    'ë² ì–´': ['bear', 'ursus'],
    'ë‘ë£¨ë¯¸': ['crane', 'grus', 'red-crowned'],
    'í¬ë ˆì¸': ['crane', 'grus'],
    'ë…ìˆ˜ë¦¬': ['eagle', 'haliaeetus', 'bald eagle'],
    'ì´ê¸€': ['eagle', 'haliaeetus'],
    'ì‚¬ì': ['lion', 'panthera leo'],
    'ë¼ì´ì–¸': ['lion', 'panthera leo'],
    'ì½”ë¼ë¦¬': ['elephant', 'elephas', 'loxodonta'],
    'ì—˜ë¦¬í€íŠ¸': ['elephant'],
    'ê¸°ë¦°': ['giraffe', 'giraffa'],
    'ê³ ë¦´ë¼': ['gorilla'],
    'ì¹¨íŒ¬ì§€': ['chimpanzee', 'pan'],
    'ëŠ‘ëŒ€': ['wolf', 'canis lupus'],
    'ì—¬ìš°': ['fox', 'vulpes'],
    'í‘œë²”': ['leopard', 'panthera pardus'],
    'ì¹˜íƒ€': ['cheetah', 'acinonyx'],
    'í•˜ì´ì—ë‚˜': ['hyena', 'crocuta'],
    'ì•…ì–´': ['crocodile', 'alligator'],
    'í­ê·„': ['penguin', 'aptenodytes'],
    'ëŒê³ ë˜': ['dolphin', 'delphinus'],
    'ê³ ë˜': ['whale', 'balaenoptera'],
    'ìƒì–´': ['shark', 'carcharodon'],
    'ë¬¼ê°œ': ['seal', 'phoca'],
    'ë°”ë‹¤í‘œë²”': ['seal', 'leopard seal'],
    'ìº¥ê±°ë£¨': ['kangaroo', 'macropus'],
    'ì½”ì•Œë¼': ['koala', 'phascolarctos'],
}

@router.get("", response_model=Dict[str, Any])
async def get_species(
    country: Optional[str] = None,
    category: Optional[str] = None,
    page: int = Query(1, ge=1),
    limit: int = Query(3, ge=1, le=100)
):
    """
    ì™¸ë¶€ API(IUCN + Wikipedia)ë¥¼ í†µí•´ ìƒë¬¼ ë‹¤ì–‘ì„± ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    if not country:
        return {"data": [], "total": 0, "page": page, "totalPages": 0}

    # IUCN API + Wikipedia API í˜¸ì¶œ
    species_list = await iucn_service.get_species_by_country(country)

    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    if category and category != "ë™ë¬¼":
        species_list = [s for s in species_list if s.get("category") == category]

    total = len(species_list)

    # í˜ì´ì§€ë„¤ì´ì…˜
    start = (page - 1) * limit
    end = start + limit
    paginated_list = species_list[start:end]

    total_pages = (total + limit - 1) // limit if total > 0 else 0

    return {
        "data": paginated_list,
        "total": total,
        "page": page,
        "totalPages": total_pages
    }

def fuzzy_match(query: str, target: str, threshold: float = 0.6) -> bool:
    """
    í¼ì§€ ë§¤ì¹­: ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ìì—´ ë¹„êµ
    threshold: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì—„ê²©)
    """
    ratio = difflib.SequenceMatcher(None, query.lower(), target.lower()).ratio()
    return ratio >= threshold

def translate_query(query: str) -> List[str]:
    """
    í•œê¸€ ê²€ìƒ‰ì–´ë¥¼ ì˜ë¬¸ìœ¼ë¡œ ë²ˆì—­
    """
    query_lower = query.lower()

    # í•œê¸€ ë§¤í•‘ ì§ì ‘ ê²€ìƒ‰
    if query_lower in SPECIES_TRANSLATIONS:
        return SPECIES_TRANSLATIONS[query_lower]

    # í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ í•œê¸€ í‚¤ì›Œë“œ ì°¾ê¸°
    for korean_key, english_terms in SPECIES_TRANSLATIONS.items():
        if fuzzy_match(query_lower, korean_key, threshold=0.7):
            print(f"ğŸ” í•œê¸€ ë§¤ì¹­: '{query}' â†’ '{korean_key}' â†’ {english_terms}")
            return english_terms

    # ì˜ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return [query]

@router.get("/search", response_model=Dict[str, Any])
async def search_species(
    query: str = Query(..., min_length=1),
    category: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    ì¢… ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ í•´ë‹¹ ì¢…ì´ ì„œì‹í•˜ëŠ” êµ­ê°€ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    - í•œê¸€ ì§€ì› (ì˜ˆ: íŒë‹¤, í˜¸ë‘ì´, ê³°)
    - ì˜¤íƒ€ í—ˆìš© (í¼ì§€ ë§¤ì¹­)
    - ë¶€ë¶„ ì¼ì¹˜ ì§€ì›
    - ë§¤ì¹­ëœ ì¢…ì˜ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜
    """
    print(f"ğŸ” ê²€ìƒ‰ ìš”ì²­: '{query}' (ì¹´í…Œê³ ë¦¬: {category})")

    # í•œê¸€ì„ ì˜ë¬¸ìœ¼ë¡œ ë²ˆì—­
    search_terms = translate_query(query)
    print(f"ğŸ“ ê²€ìƒ‰ì–´ í™•ì¥: {search_terms}")

    # ì—¬ëŸ¬ êµ­ê°€ì—ì„œ ì¢… ê²€ìƒ‰
    test_countries = ['KR', 'US', 'RU', 'CN', 'JP', 'BR', 'ID', 'IN', 'AU', 'MX']
    matching_countries = []
    matched_category = None  # ë§¤ì¹­ëœ ì¢…ì˜ ì¹´í…Œê³ ë¦¬

    for country_code in test_countries:
        species_list = await iucn_service.get_species_by_country(country_code)

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if category and category != "ë™ë¬¼":
            species_list = [s for s in species_list if s.get("category") == category]

        # ì¢… ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (common_name, scientific_name)
        for species in species_list:
            common_name = species.get("common_name", "").lower()
            scientific_name = species.get("scientific_name", "").lower()

            # ê° ê²€ìƒ‰ì–´ë¡œ ì²´í¬
            found = False
            for term in search_terms:
                term_lower = term.lower()

                # 1. ì •í™•í•œ ë¶€ë¶„ ì¼ì¹˜
                if term_lower in common_name or term_lower in scientific_name:
                    found = True
                    break

                # 2. í¼ì§€ ë§¤ì¹­ (ì˜¤íƒ€ í—ˆìš©)
                if fuzzy_match(term_lower, common_name, threshold=0.65) or \
                   fuzzy_match(term_lower, scientific_name, threshold=0.65):
                    found = True
                    break

            if found:
                if country_code not in matching_countries:
                    matching_countries.append(country_code)
                    # ì²« ë²ˆì§¸ ë§¤ì¹­ëœ ì¢…ì˜ ì¹´í…Œê³ ë¦¬ ì €ì¥
                    if matched_category is None:
                        matched_category = species.get("category", "ë™ë¬¼")
                    print(f"âœ… ë§¤ì¹­: {country_code} - {common_name} ({scientific_name}) [{matched_category}]")
                break

    print(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {len(matching_countries)}ê°œ êµ­ê°€ - {matching_countries} (ì¹´í…Œê³ ë¦¬: {matched_category})")

    # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
    try:
        search_record = SearchHistory(
            query=query,
            category=matched_category,
            result_count=len(matching_countries)
        )
        db.add(search_record)
        db.commit()
        print(f"ğŸ’¾ ê²€ìƒ‰ ê¸°ë¡ ì €ì¥: '{query}' (ê²°ê³¼: {len(matching_countries)}ê°œ)")
    except Exception as e:
        print(f"âš ï¸ ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
        db.rollback()

    return {
        "query": query,
        "countries": matching_countries,
        "total": len(matching_countries),
        "category": matched_category  # ë§¤ì¹­ëœ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
    }

@router.get("/trending", response_model=Dict[str, Any])
async def get_trending_searches(
    limit: int = Query(7, ge=1, le=20),
    hours: int = Query(24, ge=1, le=168),  # ê¸°ë³¸ 24ì‹œê°„, ìµœëŒ€ 7ì¼
    db: Session = Depends(get_db)
):
    """
    ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ë­í‚¹ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    - limit: ì¡°íšŒí•  ê²€ìƒ‰ì–´ ê°œìˆ˜ (ê¸°ë³¸ 7ê°œ)
    - hours: ì¡°íšŒ ê¸°ê°„ (ê¸°ë³¸ 24ì‹œê°„)
    """
    try:
        # íŠ¹ì • ì‹œê°„ ì´ë‚´ì˜ ê²€ìƒ‰ ê¸°ë¡ë§Œ ì¡°íšŒ
        since = datetime.utcnow() - timedelta(hours=hours)

        # ê²€ìƒ‰ì–´ë³„ ê²€ìƒ‰ íšŸìˆ˜ ì§‘ê³„ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
        trending = db.query(
            func.lower(SearchHistory.query).label('query'),
            func.count(SearchHistory.id).label('count')
        ).filter(
            SearchHistory.searched_at >= since
        ).group_by(
            func.lower(SearchHistory.query)
        ).order_by(
            func.count(SearchHistory.id).desc()
        ).limit(limit).all()

        # ê²°ê³¼ í¬ë§·íŒ…
        result = [
            {
                "rank": idx + 1,
                "query": item.query,
                "count": item.count
            }
            for idx, item in enumerate(trending)
        ]

        print(f"ğŸ“Š ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ì¡°íšŒ: {len(result)}ê°œ (ìµœê·¼ {hours}ì‹œê°„)")

        return {
            "data": result,
            "period_hours": hours,
            "total": len(result)
        }
    except Exception as e:
        print(f"âŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "data": [],
            "period_hours": hours,
            "total": 0
        }

@router.get("/endangered", response_model=Dict[str, Any])
async def get_endangered_species(
    country: str = Query(..., description="êµ­ê°€ ì½”ë“œ (ì˜ˆ: KR, US, CN)"),
    category: Optional[str] = None,
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100)
):
    """
    ë©¸ì¢…ìœ„ê¸°ì¢… ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    IUCN ìœ„í—˜ ë“±ê¸‰ì´ CR (Critically Endangered), EN (Endangered), VU (Vulnerable)ì¸ ì¢…ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        country: êµ­ê°€ ì½”ë“œ (ISO Alpha-2)
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒì‚¬í•­)
        page: í˜ì´ì§€ ë²ˆí˜¸
        limit: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜
    """
    try:
        print(f"ğŸ” ë©¸ì¢…ìœ„ê¸°ì¢… ì¡°íšŒ: {country} (ì¹´í…Œê³ ë¦¬: {category})")

        # êµ­ê°€ë³„ ì „ì²´ ì¢… ë°ì´í„° ì¡°íšŒ
        species_list = await iucn_service.get_species_by_country(country)

        # ë©¸ì¢…ìœ„ê¸°ì¢…ë§Œ í•„í„°ë§ (CR, EN, VU)
        endangered_list = [
            s for s in species_list
            if s.get("risk_level") in ["CR", "EN", "VU"]
        ]

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if category and category != "ë™ë¬¼":
            endangered_list = [s for s in endangered_list if s.get("category") == category]

        total = len(endangered_list)

        # í˜ì´ì§€ë„¤ì´ì…˜
        start = (page - 1) * limit
        end = start + limit
        paginated_list = endangered_list[start:end]

        total_pages = (total + limit - 1) // limit if total > 0 else 0

        print(f"âœ… ë©¸ì¢…ìœ„ê¸°ì¢… {total}ê°œ ë°œê²¬ (í˜„ì¬ í˜ì´ì§€: {len(paginated_list)}ê°œ)")

        return {
            "data": paginated_list,
            "total": total,
            "page": page,
            "totalPages": total_pages
        }
    except Exception as e:
        print(f"âŒ ë©¸ì¢…ìœ„ê¸°ì¢… ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "data": [],
            "total": 0,
            "page": page,
            "totalPages": 0
        }

@router.get("/{species_id}", response_model=Dict[str, Any])
async def get_species_detail(species_id: int):
    """
    íŠ¹ì • ì¢…ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    IUCN APIì™€ Wikipedia APIë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ì°¸ê³ : species_idëŠ” IUCN taxonidë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
    """
    try:
        print(f"ğŸ” ì¢… ìƒì„¸ ì •ë³´ ì¡°íšŒ: ID {species_id}")

        # IUCN APIë¥¼ í†µí•´ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        species_detail = await iucn_service.get_species_detail(species_id)

        if not species_detail:
            return {
                "error": "Species not found",
                "id": species_id
            }

        print(f"âœ… ìƒì„¸ ì •ë³´ ìˆ˜ì‹  ì™„ë£Œ: {species_detail.get('common_name', species_detail.get('scientific_name'))}")

        return species_detail
    except Exception as e:
        print(f"âŒ ì¢… ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "error": str(e),
            "id": species_id
        }
